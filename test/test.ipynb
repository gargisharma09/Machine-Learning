{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3600c306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f95e0ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Placement_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d7f919f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl_no</th>\n",
       "      <th>gender</th>\n",
       "      <th>ssc_p</th>\n",
       "      <th>ssc_b</th>\n",
       "      <th>hsc_p</th>\n",
       "      <th>hsc_b</th>\n",
       "      <th>hsc_s</th>\n",
       "      <th>degree_p</th>\n",
       "      <th>degree_t</th>\n",
       "      <th>workex</th>\n",
       "      <th>etest_p</th>\n",
       "      <th>specialisation</th>\n",
       "      <th>mba_p</th>\n",
       "      <th>status</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>67.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>91.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>58.00</td>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>No</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Mkt&amp;HR</td>\n",
       "      <td>58.80</td>\n",
       "      <td>Placed</td>\n",
       "      <td>270000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>79.33</td>\n",
       "      <td>Central</td>\n",
       "      <td>78.33</td>\n",
       "      <td>Others</td>\n",
       "      <td>Science</td>\n",
       "      <td>77.48</td>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>Yes</td>\n",
       "      <td>86.5</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>66.28</td>\n",
       "      <td>Placed</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>65.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>68.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>Arts</td>\n",
       "      <td>64.00</td>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>No</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>57.80</td>\n",
       "      <td>Placed</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>56.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>52.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>Science</td>\n",
       "      <td>52.00</td>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>No</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Mkt&amp;HR</td>\n",
       "      <td>59.43</td>\n",
       "      <td>Not Placed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>85.80</td>\n",
       "      <td>Central</td>\n",
       "      <td>73.60</td>\n",
       "      <td>Central</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>73.30</td>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>No</td>\n",
       "      <td>96.8</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>55.50</td>\n",
       "      <td>Placed</td>\n",
       "      <td>425000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sl_no gender  ssc_p    ssc_b  hsc_p    hsc_b     hsc_s  degree_p  \\\n",
       "0      1      M  67.00   Others  91.00   Others  Commerce     58.00   \n",
       "1      2      M  79.33  Central  78.33   Others   Science     77.48   \n",
       "2      3      M  65.00  Central  68.00  Central      Arts     64.00   \n",
       "3      4      M  56.00  Central  52.00  Central   Science     52.00   \n",
       "4      5      M  85.80  Central  73.60  Central  Commerce     73.30   \n",
       "\n",
       "    degree_t workex  etest_p specialisation  mba_p      status    salary  \n",
       "0   Sci&Tech     No     55.0         Mkt&HR  58.80      Placed  270000.0  \n",
       "1   Sci&Tech    Yes     86.5        Mkt&Fin  66.28      Placed  200000.0  \n",
       "2  Comm&Mgmt     No     75.0        Mkt&Fin  57.80      Placed  250000.0  \n",
       "3   Sci&Tech     No     66.0         Mkt&HR  59.43  Not Placed       NaN  \n",
       "4  Comm&Mgmt     No     96.8        Mkt&Fin  55.50      Placed  425000.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2633b3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sl_no              0\n",
       "gender             0\n",
       "ssc_p              0\n",
       "ssc_b              0\n",
       "hsc_p              0\n",
       "hsc_b              0\n",
       "hsc_s              0\n",
       "degree_p           0\n",
       "degree_t           0\n",
       "workex             0\n",
       "etest_p            0\n",
       "specialisation     0\n",
       "mba_p              0\n",
       "status             0\n",
       "salary            67\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3538fbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sharm\\AppData\\Local\\Temp\\ipykernel_18448\\3099058985.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['salary'].fillna(data['salary'].mean(),inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data['salary'].fillna(data['salary'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d1bb1c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sl_no             0\n",
       "gender            0\n",
       "ssc_p             0\n",
       "ssc_b             0\n",
       "hsc_p             0\n",
       "hsc_b             0\n",
       "hsc_s             0\n",
       "degree_p          0\n",
       "degree_t          0\n",
       "workex            0\n",
       "etest_p           0\n",
       "specialisation    0\n",
       "mba_p             0\n",
       "status            0\n",
       "salary            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "075a72a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "18cb10d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aee627ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sl_no               int64\n",
       "gender             object\n",
       "ssc_p             float64\n",
       "ssc_b              object\n",
       "hsc_p             float64\n",
       "hsc_b              object\n",
       "hsc_s              object\n",
       "degree_p          float64\n",
       "degree_t           object\n",
       "workex             object\n",
       "etest_p           float64\n",
       "specialisation     object\n",
       "mba_p             float64\n",
       "status             object\n",
       "salary            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "47cf30db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl_no</th>\n",
       "      <th>gender</th>\n",
       "      <th>ssc_p</th>\n",
       "      <th>ssc_b</th>\n",
       "      <th>hsc_p</th>\n",
       "      <th>hsc_b</th>\n",
       "      <th>hsc_s</th>\n",
       "      <th>degree_p</th>\n",
       "      <th>degree_t</th>\n",
       "      <th>workex</th>\n",
       "      <th>etest_p</th>\n",
       "      <th>specialisation</th>\n",
       "      <th>mba_p</th>\n",
       "      <th>status</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>67.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>91.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>58.00</td>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>No</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Mkt&amp;HR</td>\n",
       "      <td>58.80</td>\n",
       "      <td>Placed</td>\n",
       "      <td>270000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>79.33</td>\n",
       "      <td>Central</td>\n",
       "      <td>78.33</td>\n",
       "      <td>Others</td>\n",
       "      <td>Science</td>\n",
       "      <td>77.48</td>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>Yes</td>\n",
       "      <td>86.5</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>66.28</td>\n",
       "      <td>Placed</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>65.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>68.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>Arts</td>\n",
       "      <td>64.00</td>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>No</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>57.80</td>\n",
       "      <td>Placed</td>\n",
       "      <td>250000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>56.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>52.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>Science</td>\n",
       "      <td>52.00</td>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>No</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Mkt&amp;HR</td>\n",
       "      <td>59.43</td>\n",
       "      <td>Not Placed</td>\n",
       "      <td>288655.405405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>85.80</td>\n",
       "      <td>Central</td>\n",
       "      <td>73.60</td>\n",
       "      <td>Central</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>73.30</td>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>No</td>\n",
       "      <td>96.8</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>55.50</td>\n",
       "      <td>Placed</td>\n",
       "      <td>425000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sl_no gender  ssc_p    ssc_b  hsc_p    hsc_b     hsc_s  degree_p  \\\n",
       "0      1      M  67.00   Others  91.00   Others  Commerce     58.00   \n",
       "1      2      M  79.33  Central  78.33   Others   Science     77.48   \n",
       "2      3      M  65.00  Central  68.00  Central      Arts     64.00   \n",
       "3      4      M  56.00  Central  52.00  Central   Science     52.00   \n",
       "4      5      M  85.80  Central  73.60  Central  Commerce     73.30   \n",
       "\n",
       "    degree_t workex  etest_p specialisation  mba_p      status         salary  \n",
       "0   Sci&Tech     No     55.0         Mkt&HR  58.80      Placed  270000.000000  \n",
       "1   Sci&Tech    Yes     86.5        Mkt&Fin  66.28      Placed  200000.000000  \n",
       "2  Comm&Mgmt     No     75.0        Mkt&Fin  57.80      Placed  250000.000000  \n",
       "3   Sci&Tech     No     66.0         Mkt&HR  59.43  Not Placed  288655.405405  \n",
       "4  Comm&Mgmt     No     96.8        Mkt&Fin  55.50      Placed  425000.000000  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7cffcc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries —> null —> duplicates ~> encode —> outlier —> traintestsplit —> standardization —> model —> evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5756f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f4db2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "07b8b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = label.fit_transform(data.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "94f75ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['status'] = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "492be72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = label.fit_transform(data.gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "777430ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gender'] = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c7287452",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = label.fit_transform(data.hsc_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6e9ab8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hsc_b'] = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0e3c8e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = label.fit_transform(data.hsc_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7d54e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hsc_s'] = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "70e39890",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = label.fit_transform(data.degree_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6c839519",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['degree_t'] = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9707fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = label.fit_transform(data.workex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a002933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['workex'] = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3a7c2076",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = label.fit_transform(data.ssc_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dcd0c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ssc_b'] = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "856a8176",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = label.fit_transform(data.specialisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8952e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['specialisation'] = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "27739a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl_no</th>\n",
       "      <th>gender</th>\n",
       "      <th>ssc_p</th>\n",
       "      <th>ssc_b</th>\n",
       "      <th>hsc_p</th>\n",
       "      <th>hsc_b</th>\n",
       "      <th>hsc_s</th>\n",
       "      <th>degree_p</th>\n",
       "      <th>degree_t</th>\n",
       "      <th>workex</th>\n",
       "      <th>etest_p</th>\n",
       "      <th>specialisation</th>\n",
       "      <th>mba_p</th>\n",
       "      <th>status</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>91.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>58.80</td>\n",
       "      <td>1</td>\n",
       "      <td>270000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>78.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>77.48</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>86.5</td>\n",
       "      <td>0</td>\n",
       "      <td>66.28</td>\n",
       "      <td>1</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>68.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.80</td>\n",
       "      <td>1</td>\n",
       "      <td>250000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>52.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.43</td>\n",
       "      <td>0</td>\n",
       "      <td>288655.405405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>73.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.8</td>\n",
       "      <td>0</td>\n",
       "      <td>55.50</td>\n",
       "      <td>1</td>\n",
       "      <td>346638.513514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sl_no  gender  ssc_p  ssc_b  hsc_p  hsc_b  hsc_s  degree_p  degree_t  \\\n",
       "0      1       1     46      1  91.00      1      1     58.00         2   \n",
       "1      2       1     82      0  78.33      1      2     77.48         2   \n",
       "2      3       1     42      0  68.00      0      0     64.00         0   \n",
       "3      4       1     22      0  52.00      0      2     52.00         2   \n",
       "4      5       1     98      0  73.60      0      1     73.30         0   \n",
       "\n",
       "   workex  etest_p  specialisation  mba_p  status         salary  \n",
       "0       0     55.0               1  58.80       1  270000.000000  \n",
       "1       1     86.5               0  66.28       1  200000.000000  \n",
       "2       0     75.0               0  57.80       1  250000.000000  \n",
       "3       0     66.0               0  59.43       0  288655.405405  \n",
       "4       0     96.8               0  55.50       1  346638.513514  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bc6d9b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "specialisation\n",
       "0    116\n",
       "1     99\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['specialisation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "91033983",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = data.select_dtypes(include='number').columns\n",
    "\n",
    "for col in numeric:\n",
    "    q1 = data[col].quantile(0.25)\n",
    "    q3 = data[col].quantile(0.75)\n",
    "    iqr = q3 - q1 \n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr \n",
    "\n",
    "    data[col] = data[col].clip(lower = lower,upper = upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c9af8f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl_no</th>\n",
       "      <th>gender</th>\n",
       "      <th>ssc_p</th>\n",
       "      <th>ssc_b</th>\n",
       "      <th>hsc_p</th>\n",
       "      <th>hsc_b</th>\n",
       "      <th>hsc_s</th>\n",
       "      <th>degree_p</th>\n",
       "      <th>degree_t</th>\n",
       "      <th>workex</th>\n",
       "      <th>etest_p</th>\n",
       "      <th>specialisation</th>\n",
       "      <th>mba_p</th>\n",
       "      <th>status</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.646512</td>\n",
       "      <td>49.474419</td>\n",
       "      <td>0.460465</td>\n",
       "      <td>66.334744</td>\n",
       "      <td>0.609302</td>\n",
       "      <td>1.372093</td>\n",
       "      <td>66.358558</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.344186</td>\n",
       "      <td>72.100558</td>\n",
       "      <td>0.460465</td>\n",
       "      <td>62.278186</td>\n",
       "      <td>0.688372</td>\n",
       "      <td>277478.488372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>62.209324</td>\n",
       "      <td>0.479168</td>\n",
       "      <td>26.572912</td>\n",
       "      <td>0.499598</td>\n",
       "      <td>10.586016</td>\n",
       "      <td>0.489045</td>\n",
       "      <td>0.580978</td>\n",
       "      <td>7.321524</td>\n",
       "      <td>0.890238</td>\n",
       "      <td>0.476211</td>\n",
       "      <td>13.275956</td>\n",
       "      <td>0.499598</td>\n",
       "      <td>5.833385</td>\n",
       "      <td>0.464240</td>\n",
       "      <td>37674.434641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.210000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.945000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>108.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>288655.405405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>161.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>83.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>66.255000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>288655.405405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>215.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91.150000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>88.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>77.890000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>346638.513514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sl_no      gender       ssc_p       ssc_b       hsc_p       hsc_b  \\\n",
       "count  215.000000  215.000000  215.000000  215.000000  215.000000  215.000000   \n",
       "mean   108.000000    0.646512   49.474419    0.460465   66.334744    0.609302   \n",
       "std     62.209324    0.479168   26.572912    0.499598   10.586016    0.489045   \n",
       "min      1.000000    0.000000    0.000000    0.000000   42.750000    0.000000   \n",
       "25%     54.500000    0.000000   31.500000    0.000000   60.900000    0.000000   \n",
       "50%    108.000000    1.000000   46.000000    0.000000   65.000000    1.000000   \n",
       "75%    161.500000    1.000000   69.500000    1.000000   73.000000    1.000000   \n",
       "max    215.000000    1.000000  102.000000    1.000000   91.150000    1.000000   \n",
       "\n",
       "            hsc_s    degree_p    degree_t      workex     etest_p  \\\n",
       "count  215.000000  215.000000  215.000000  215.000000  215.000000   \n",
       "mean     1.372093   66.358558    0.600000    0.344186   72.100558   \n",
       "std      0.580978    7.321524    0.890238    0.476211   13.275956   \n",
       "min      0.000000   50.000000    0.000000    0.000000   50.000000   \n",
       "25%      1.000000   61.000000    0.000000    0.000000   60.000000   \n",
       "50%      1.000000   66.000000    0.000000    0.000000   71.000000   \n",
       "75%      2.000000   72.000000    2.000000    1.000000   83.500000   \n",
       "max      2.000000   88.500000    2.000000    1.000000   98.000000   \n",
       "\n",
       "       specialisation       mba_p      status         salary  \n",
       "count      215.000000  215.000000  215.000000     215.000000  \n",
       "mean         0.460465   62.278186    0.688372  277478.488372  \n",
       "std          0.499598    5.833385    0.464240   37674.434641  \n",
       "min          0.000000   51.210000    0.000000  200000.000000  \n",
       "25%          0.000000   57.945000    0.000000  250000.000000  \n",
       "50%          0.000000   62.000000    1.000000  288655.405405  \n",
       "75%          1.000000   66.255000    1.000000  288655.405405  \n",
       "max          1.000000   77.890000    1.000000  346638.513514  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e9d43139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sl_no               int64\n",
       "gender              int64\n",
       "ssc_p               int64\n",
       "ssc_b               int64\n",
       "hsc_p             float64\n",
       "hsc_b               int64\n",
       "hsc_s               int64\n",
       "degree_p          float64\n",
       "degree_t            int64\n",
       "workex              int64\n",
       "etest_p           float64\n",
       "specialisation      int64\n",
       "mba_p             float64\n",
       "status              int64\n",
       "salary            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c96411ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a24a0fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('status',axis=1)\n",
    "Y = data['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a942f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a9a0303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "692869f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "73ee4952",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "300f25e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4b1d6915",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1e97718d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bde7a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target1 = lr.predict(X_train)\n",
    "target2 = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8a5260f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "39251c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 88.95348837209302\n",
      "Testing  accuracy: 86.04651162790698\n"
     ]
    }
   ],
   "source": [
    "print('Training accuracy:', accuracy_score(Y_train,target1)*100)\n",
    "print('Testing  accuracy:', accuracy_score(Y_test,target2)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b58c52e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "71a87abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82        55\n",
      "           1       0.90      0.95      0.92       117\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.89      0.86      0.87       172\n",
      "weighted avg       0.89      0.89      0.89       172\n",
      "\n",
      "Testing  report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.88      0.94      0.91        31\n",
      "\n",
      "    accuracy                           0.86        43\n",
      "   macro avg       0.84      0.80      0.82        43\n",
      "weighted avg       0.86      0.86      0.86        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training report:', classification_report(Y_train,target1)*100)\n",
    "print('Testing  report:', classification_report(Y_test,target2)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41da135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
